Our IoT system is built to scale smoothly from a single home to thousands without needing to redesign the architecture. Each household gets its own `house_id`, which keeps data streams cleanly separated and makes it easy to scale ingestion, storage, and analytics horizontally. At the edge, sensor data is published using lightweight MQTT topics (for example, `house/{house_id}/mains`), which works well with clustered or managed IoT brokers that can support large numbers of simultaneous connections.

In the cloud, we partition time‑series data by both household and time window. This structure allows parallel writes and fast queries, whether we’re looking at real‑time data or running historical analyses. Stream processors and serverless functions can be scaled out as message volume increases, and object storage gives us effectively unlimited room for raw and processed data. Our machine learning models—both the CNN for NILM and the LSTM for forecasting—run as containerized or serverless workloads, which means they automatically scale based on demand.

Overall, this design lets us scale compute, storage, and messaging independently. As the number of participating households grows, the system can expand in a controlled, modular way while still maintaining strong performance and reliability across a large, distributed user base.
